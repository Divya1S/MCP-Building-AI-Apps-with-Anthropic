{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc712d2-8b62-4098-a986-76ec60c795c4",
   "metadata": {},
   "source": [
    "# Connecting the MCP Chatbot to Reference Servers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7159b5-02ba-413a-b30c-4f7725379c46",
   "metadata": {},
   "source": [
    "## Updated Code for the MCP Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee81457-ab55-4acb-9dc6-6b4443344d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_project/mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_project/mcp_chatbot.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, TypedDict\n",
    "from contextlib import AsyncExitStack\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "class MCP_ChatBot:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize session and client objects\n",
    "        self.sessions: List[ClientSession] = [] # new\n",
    "        self.exit_stack = AsyncExitStack() # new\n",
    "        self.anthropic = Anthropic()\n",
    "        self.available_tools: List[ToolDefinition] = [] # new\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {} # new\n",
    "\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_config: dict) -> None:\n",
    "        \"\"\"Connect to a single MCP server.\"\"\"\n",
    "        try:\n",
    "            server_params = StdioServerParameters(**server_config)\n",
    "            stdio_transport = await self.exit_stack.enter_async_context(\n",
    "                stdio_client(server_params)\n",
    "            ) # new\n",
    "            read, write = stdio_transport\n",
    "            session = await self.exit_stack.enter_async_context(\n",
    "                ClientSession(read, write)\n",
    "            ) # new\n",
    "            await session.initialize()\n",
    "            self.sessions.append(session)\n",
    "            \n",
    "            # List available tools for this session\n",
    "            response = await session.list_tools()\n",
    "            tools = response.tools\n",
    "            print(f\"\\nConnected to {server_name} with tools:\", [t.name for t in tools])\n",
    "            \n",
    "            for tool in tools: # new\n",
    "                self.tool_to_session[tool.name] = session\n",
    "                self.available_tools.append({\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"input_schema\": tool.inputSchema\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self): # new\n",
    "        \"\"\"Connect to all configured MCP servers.\"\"\"\n",
    "        try:\n",
    "            with open(\"server_config.json\", \"r\") as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            servers = data.get(\"mcpServers\", {})\n",
    "            \n",
    "            for server_name, server_config in servers.items():\n",
    "                await self.connect_to_server(server_name, server_config)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading server configuration: {e}\")\n",
    "            raise\n",
    "    \n",
    "    async def process_query(self, query):\n",
    "        messages = [{'role':'user', 'content':query}]\n",
    "        response = self.anthropic.messages.create(max_tokens = 2024,\n",
    "                                      model = 'claude-3-7-sonnet-20250219', \n",
    "                                      tools = self.available_tools,\n",
    "                                      messages = messages)\n",
    "        process_query = True\n",
    "        while process_query:\n",
    "            assistant_content = []\n",
    "            for content in response.content:\n",
    "                if content.type =='text':\n",
    "                    print(content.text)\n",
    "                    assistant_content.append(content)\n",
    "                    if(len(response.content) == 1):\n",
    "                        process_query= False\n",
    "                elif content.type == 'tool_use':\n",
    "                    assistant_content.append(content)\n",
    "                    messages.append({'role':'assistant', 'content':assistant_content})\n",
    "                    tool_id = content.id\n",
    "                    tool_args = content.input\n",
    "                    tool_name = content.name\n",
    "                    \n",
    "    \n",
    "                    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                    \n",
    "                    # Call a tool\n",
    "                    session = self.tool_to_session[tool_name] # new\n",
    "                    result = await session.call_tool(tool_name, arguments=tool_args)\n",
    "                    messages.append({\"role\": \"user\", \n",
    "                                      \"content\": [\n",
    "                                          {\n",
    "                                              \"type\": \"tool_result\",\n",
    "                                              \"tool_use_id\":tool_id,\n",
    "                                              \"content\": result.content\n",
    "                                          }\n",
    "                                      ]\n",
    "                                    })\n",
    "                    response = self.anthropic.messages.create(max_tokens = 2024,\n",
    "                                      model = 'claude-3-7-sonnet-20250219', \n",
    "                                      tools = self.available_tools,\n",
    "                                      messages = messages) \n",
    "                    \n",
    "                    if(len(response.content) == 1 and response.content[0].type == \"text\"):\n",
    "                        print(response.content[0].text)\n",
    "                        process_query= False\n",
    "\n",
    "    \n",
    "    \n",
    "    async def chat_loop(self):\n",
    "        \"\"\"Run an interactive chat loop\"\"\"\n",
    "        print(\"\\nMCP Chatbot Started!\")\n",
    "        print(\"Type your queries or 'quit' to exit.\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                query = input(\"\\nQuery: \").strip()\n",
    "        \n",
    "                if query.lower() == 'quit':\n",
    "                    break\n",
    "                    \n",
    "                await self.process_query(query)\n",
    "                print(\"\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {str(e)}\")\n",
    "    \n",
    "    async def cleanup(self): # new\n",
    "        \"\"\"Cleanly close all resources using AsyncExitStack.\"\"\"\n",
    "        await self.exit_stack.aclose()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    try:\n",
    "        # the mcp clients and sessions are not initialized using \"with\"\n",
    "        # like in the previous lesson\n",
    "        # so the cleanup should be manually handled\n",
    "        await chatbot.connect_to_servers() # new! \n",
    "        await chatbot.chat_loop()\n",
    "    finally:\n",
    "        await chatbot.cleanup() #new! \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f221f83-6e8b-431e-bd27-6dccedfac408",
   "metadata": {},
   "source": [
    "## Running the MCP Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c35e59-61ba-4bc5-a13f-3022a4e0fced",
   "metadata": {},
   "source": [
    "**Terminal Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bf05b-10ce-4576-9717-6870a4cfd701",
   "metadata": {},
   "source": [
    "- To open the terminal, run the cell below.\n",
    "- Navigate to the `mcp_project` directory:\n",
    "    - `cd L6/mcp_project`\n",
    "- Activate the virtual environment:\n",
    "    - `source .venv/bin/activate`\n",
    "- Run the chatbot:\n",
    "    - `uv run mcp_chatbot.py`\n",
    "- To exit the chatbot, type `quit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afe864e-e394-4366-9497-ae115d40c0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"768\"\n",
       "            src=\"https://s172-29-90-234p8888.lab-aws-production.deeplearning.ai/terminals/3\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efc9ca97990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/3\", width=600, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21edb4-aba4-4b5a-b3c6-8aa908a7c8df",
   "metadata": {},
   "source": [
    "Make sure to interact with the chatbot. Here are some query examples:\n",
    "- Fetch the content of this website: https://modelcontextprotocol.io/docs/concepts/architecture and save the content in the file \"mcp_summary.md\", create a visual diagram that summarizes the content of \"mcp_summary.md\" and save it in a text file\n",
    "- Fetch deeplearning.ai and find an interesting term. Search for 2 papers around the term and then summarize your findings and write them to a file called results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289248c2-51f6-4ccf-ab7e-3c645631f88d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3cce2-111c-4338-b117-fcc5aeece8a3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> â¬‡ &nbsp; <b>To Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4f772-91a7-487b-a52c-ebceb1397434",
   "metadata": {},
   "source": [
    "## Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a5889-4aea-406f-96eb-8d318d54a01c",
   "metadata": {},
   "source": [
    "You are encouraged to refactor the code of `MCP_ChatBot` if you'd like:\n",
    "\n",
    "- how to connect to servers asynchronously\n",
    "- what if tools from different servers have the same name\n",
    "- revisit the attributes\n",
    "  \n",
    "And maybe any other idea you may think of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff6e3f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
